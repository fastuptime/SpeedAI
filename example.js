require('dotenv').config();

// Debug modu
const DEBUG_MODE = process.env.DEBUG_MODE === 'true' ? true : false;

// AI servisi
let ai;

// Servis import
try {
  ai = require('speed-ai');
  if (!ai) throw new Error('AI servisi boÅŸ referans dÃ¶ndÃ¼rdÃ¼');
  console.log('âœ… AI servisi baÅŸarÄ±yla yÃ¼klendi');
} catch (error) {
  console.error("âŒ AI servisi yÃ¼klenemedi:", error.message);
  if (DEBUG_MODE) console.error("DetaylÄ± hata:", error);
  process.exit(1); // Servis yÃ¼klenemezse programdan Ã§Ä±k
}

function temizHataMesaji(error) {
  if (!error) return "Bilinmeyen hata";
  
  if (error.message && error.message.includes("API key")) {
    return "API anahtarÄ± hatasÄ±: API anahtarÄ± geÃ§erli deÄŸil veya saÄŸlanmadÄ±";
  }
  
  if (error.message && (error.message.includes("not a constructor") || error.message.includes("import"))) {
    return "ModÃ¼l hatasÄ±: Paket yÃ¼klemesi baÅŸarÄ±sÄ±z oldu, 'npm install' komutunu tekrar Ã§alÄ±ÅŸtÄ±rÄ±n";
  }
  
  return error.message || "Bir hata oluÅŸtu";
}

async function testOpenAI() {
  console.log("\nğŸ” OPENAI TEST\n" + "=".repeat(30));
  const prompt = "Merhaba, Ã¼rÃ¼n iadesini nasÄ±l yapabilirim?";
  const apiKey = process.env.OPENAI_API_KEY;
  const model = "gpt-3.5-turbo-instruct";
  
  try {
    console.log("Prompt: ", prompt);
    
    const response = await ai.completePrompt('openai', prompt, apiKey, model, {
      temperature: 0.7,
      maxTokens: 250
    });
    
    // Ä°stenen JSON formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    const formattedResponse = {
      status: true,
      provider: "openai",
      message: response.text,
      model: response.model,
      usage: response.usage || null
    };
    
    console.log("\nâœ… OPENAI YANITI");
    console.log(JSON.stringify(formattedResponse, null, 2));
    
  } catch (error) {
    const errorResponse = {
      status: false,
      provider: "openai",
      message: temizHataMesaji(error),
      error: DEBUG_MODE ? error.message : null
    };
    
    console.log("\nâŒ OPENAI HATASI");
    console.log(JSON.stringify(errorResponse, null, 2));
    
    if (DEBUG_MODE) {
      console.error("DetaylÄ± hata:", error);
    }
  }
}

async function testMistral() {
  console.log("\nğŸ” MISTRAL TEST\n" + "=".repeat(30));
  const prompt = "Merhaba, Ã¼rÃ¼n iadesini nasÄ±l yapabilirim?";
  const apiKey = process.env.MISTRAL_API_KEY;
  const model = "mistral-tiny";
  
  try {
    console.log("Prompt: ", prompt);
    
    const messages = [{ role: "user", content: prompt }];
    const response = await ai.chat('mistral', messages, apiKey, model, {
      temperature: 0.7
    });
    
    // Ä°stenen JSON formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    const formattedResponse = {
      status: true,
      provider: "mistral",
      message: response.message.content,
      model: response.model,
      usage: response.usage || null
    };
    
    console.log("\nâœ… MISTRAL YANITI");
    console.log(JSON.stringify(formattedResponse, null, 2));
    
  } catch (error) {
    const errorResponse = {
      status: false,
      provider: "mistral",
      message: temizHataMesaji(error),
      error: DEBUG_MODE ? error.message : null
    };
    
    console.log("\nâŒ MISTRAL HATASI");
    console.log(JSON.stringify(errorResponse, null, 2));
    
    if (DEBUG_MODE) {
      console.error("DetaylÄ± hata:", error);
    }
  }
}

async function testDeepseek() {
  console.log("\nğŸ” DEEPSEEK TEST\n" + "=".repeat(30));
  const prompt = "Merhaba, Ã¼rÃ¼n iadesini nasÄ±l yapabilirim?";
  const apiKey = process.env.DEEPSEEK_API_KEY;
  const model = "deepseek-coder";
  
  try {
    console.log("Prompt: ", prompt);
    
    const response = await ai.completePrompt('deepseek', prompt, apiKey, model, {
      temperature: 0.7,
      maxTokens: 250
    });
    
    // Ä°stenen JSON formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    const formattedResponse = {
      status: true,
      provider: "deepseek",
      message: response.text,
      model: response.model,
      usage: response.usage || null
    };
    
    console.log("\nâœ… DEEPSEEK YANITI");
    console.log(JSON.stringify(formattedResponse, null, 2));
    
  } catch (error) {
    const errorResponse = {
      status: false,
      provider: "deepseek",
      message: temizHataMesaji(error),
      error: DEBUG_MODE ? error.message : null
    };
    
    console.log("\nâŒ DEEPSEEK HATASI");
    console.log(JSON.stringify(errorResponse, null, 2));
    
    if (DEBUG_MODE) {
      console.error("DetaylÄ± hata:", error);
    }
  }
}

async function testAnthropicChat() {
  console.log("\nğŸ” ANTHROPIC TEST\n" + "=".repeat(30));
  const prompt = "Merhaba, Ã¼rÃ¼n iadesini nasÄ±l yapabilirim?";
  const apiKey = process.env.ANTHROPIC_API_KEY;
  const model = "claude-2";
  
  try {
    console.log("Prompt: ", prompt);
    
    const messages = [{ role: "user", content: prompt }];
    const response = await ai.chat('anthropic', messages, apiKey, model, {
      temperature: 0.7,
      maxTokens: 250
    });
    
    // Ä°stenen JSON formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    const formattedResponse = {
      status: true,
      provider: "anthropic",
      message: response.message.content,
      model: response.model
    };
    
    console.log("\nâœ… ANTHROPIC YANITI");
    console.log(JSON.stringify(formattedResponse, null, 2));
    
  } catch (error) {
    const errorResponse = {
      status: false,
      provider: "anthropic",
      message: temizHataMesaji(error),
      error: DEBUG_MODE ? error.message : null
    };
    
    console.log("\nâŒ ANTHROPIC HATASI");
    console.log(JSON.stringify(errorResponse, null, 2));
    
    if (DEBUG_MODE) {
      console.error("DetaylÄ± hata:", error);
    }
  }
}

async function testGemini() {
  console.log("\nğŸ” GEMINI TEST\n" + "=".repeat(30));
  const prompt = "Merhaba, Ã¼rÃ¼n iadesini nasÄ±l yapabilirim?";
  const apiKey = process.env.GEMINI_API_KEY;
  const model = "gemini-2.0-flash";
  
  try {
    console.log("Prompt: ", prompt);
    
    const response = await ai.completePrompt('gemini', prompt, apiKey, model, {
      temperature: 0.7
    });
    
    // Ä°stenen JSON formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    const formattedResponse = {
      status: true,
      provider: "gemini",
      message: response.text,
      model: response.model
    };
    
    console.log("\nâœ… GEMINI YANITI");
    console.log(JSON.stringify(formattedResponse, null, 2));
    
  } catch (error) {
    const errorResponse = {
      status: false,
      provider: "gemini",
      message: temizHataMesaji(error),
      error: DEBUG_MODE ? error.message : null
    };
    
    console.log("\nâŒ GEMINI HATASI");
    console.log(JSON.stringify(errorResponse, null, 2));
    
    if (DEBUG_MODE) {
      console.error("DetaylÄ± hata:", error);
    }
  }
}

async function main() {
  console.log("\nğŸ¤– SPEED-AI TEST");
  
  try {
    await testOpenAI();
    await testMistral();
    await testDeepseek();
    await testAnthropicChat();
    await testGemini();
  } catch (error) {
    console.log("\nâŒ PROGRAM HATASI");
    console.log(temizHataMesaji(error));
  }
}

main();
